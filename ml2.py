# -*- coding: utf-8 -*-
"""ml2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dPea4I5bZHSBGY7u0hsUU57-U_M_PiXv
"""

# Step 1: Setup
!pip install tensorflow keras matplotlib numpy pandas scikit-learn gradio --quiet

# Step 2: Import libraries
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import os

import zipfile
import os

# Step 1: Extract the zip
zip_path = "/content/flowerdatasetzip.zip"
extract_path = "/content/flower_images"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Step 2: Verify contents
for root, dirs, files in os.walk(extract_path):
    level = root.replace(extract_path, '').count(os.sep)
    indent = ' ' * 4 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = ' ' * 4 * (level + 1)
    for f in files[:5]:  # Show first 5 files per folder
        print(f"{subindent}{f}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define paths
data_dir = "/content/flower_images"

# Preprocess images ‚Äî rescale pixel values
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2  # 80% train, 20% validation
)

# Load training data
train_data = datagen.flow_from_directory(
    data_dir,
    target_size=(150, 150),  # resize all to 150x150 pixels
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

# Load validation data
val_data = datagen.flow_from_directory(
    data_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Build the CNN model
cnn_model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')  # 3 output classes
])

# Compile the model
cnn_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

# Summary of the model
cnn_model.summary()

# Train the CNN
history = cnn_model.fit(
    train_data,
    validation_data=val_data,
    epochs=10,
    verbose=1
)

from keras.preprocessing.image import ImageDataGenerator

# Train generator with augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Validation generator (no augmentation)
val_datagen = ImageDataGenerator(rescale=1./255)

train_data = train_datagen.flow_from_directory(
    '/content/flowers/train',
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

val_data = val_datagen.flow_from_directory(
    '/content/flowers/validation',
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical'
)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras.utils import image_dataset_from_directory

dataset_path = '/content/flower_images'  # üëà change if your folder name is different

train_ds = image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,   # 80% train, 20% validation
    subset="training",
    seed=42,
    image_size=(150, 150),
    batch_size=32
)

val_ds = image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="validation",
    seed=42,
    image_size=(150, 150),
    batch_size=32
)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models

# Build CNN model
model = models.Sequential([
    layers.Rescaling(1./255, input_shape=(150,150,3)),

    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(3, activation='softmax')  # 3 flower classes
])

# Compile
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Train
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=15
)

# ‚úÖ Save the trained CNN model
model.save("iris_model.h5")
print("‚úÖ Model saved successfully as iris_model.h5")

import matplotlib.pyplot as plt

# Accuracy graph
plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Loss graph
plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

from google.colab import files
uploaded = files.upload()

import numpy as np
from tensorflow.keras.preprocessing import image

# Change this to your uploaded file name
img_path = list(uploaded.keys())[0]

# Load and preprocess
img = image.load_img(img_path, target_size=(150, 150))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0) / 255.0

# Prediction
predictions = model.predict(img_array)
pred_class = np.argmax(predictions[0])

# Class mapping (make sure it matches your dataset folder names)
class_names = train_ds.class_names

print("Predicted flower species:", class_names[pred_class])

print(train_ds.class_names)

import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.preprocessing import image

# Load image
img_path = list(uploaded.keys())[0]
img = image.load_img(img_path, target_size=(150, 150))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0) / 255.0

# Prediction
predictions = model.predict(img_array)
pred_class = np.argmax(predictions[0])

# Get class names from dataset
class_names = train_ds.class_names

# Show results
plt.imshow(image.load_img(img_path))
plt.axis('off')
plt.title(f"Predicted: {class_names[pred_class]}")
plt.show()

print("All class probabilities:")
for i, name in enumerate(class_names):
    print(f"{name}: {predictions[0][i]:.4f}")

import gradio as gr
from tensorflow.keras.models import load_model
import numpy as np

# Load model
model = load_model("iris_model.h5")

# Class names (check order using train_data.class_indices if unsure)
class_labels = ['iris-setosa', 'iris-versicolour', 'iris-virginica']

def predict_flower(img):
    try:
        img = img.resize((150, 150))
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        preds = model.predict(img_array)[0]  # probabilities
        confidence_scores = {class_labels[i]: float(preds[i]) for i in range(len(class_labels))}
        return confidence_scores
    except Exception as e:
        return {"Error": str(e)}

# ‚úÖ Gradio interface
interface = gr.Interface(
    fn=predict_flower,
    inputs=gr.Image(type="pil", label="Upload an Iris Flower üå∏"),
    outputs=gr.Label(num_top_classes=3, label="Prediction"),
    title="üåº Iris Flower CNN Classifier",
    description="Upload an image of an Iris flower to predict its species.",
)

interface.launch(share=True)

print(train_data.class_indices)

from tensorflow.keras.preprocessing import image

# Load a test image (make sure it's clearly a Setosa or Virginica)
img_path = "/content/flowers/val/iris-setosa/image1.jpg"  # change path
img = image.load_img(img_path, target_size=(150, 150))
x = np.expand_dims(image.img_to_array(img) / 255.0, axis=0)

pred = model.predict(x)
print("Raw predictions:", pred)
print("Predicted class:", class_labels[np.argmax(pred)])

from google.colab import files
uploaded = files.upload()

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

# Path of uploaded image
img_path = "iris-1f941001f508ff1bd492457a90da64e52c461bfd64587a3cf7c6bf1bcb35adab.jpg"

# Load and preprocess image
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0) / 255.0

# Predict
pred = model.predict(x)
class_labels = {0: 'iris-setosa', 1: 'iris-versicolour', 2: 'iris-virginica'}

# Display result
plt.imshow(image.load_img(img_path))
plt.axis('off')
plt.title(f"Predicted: {class_labels[np.argmax(pred)]}")
plt.show()

print("Predicted class:", class_labels[np.argmax(pred)])

# 1) Evaluate on validation dataset and collect predictions
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Make sure val_ds yields batches of (images, labels) with integer labels
# Convert val_ds to arrays (may take a bit of memory but fine for 84 images)
y_true = []
y_pred = []
for batch_images, batch_labels in val_ds:
    preds = model.predict(batch_images)
    preds_idx = np.argmax(preds, axis=1)
    # if labels are one-hot, convert to ints; if sparse, they are already ints
    if batch_labels.ndim == 2:
        true_idx = np.argmax(batch_labels, axis=1)
    else:
        true_idx = batch_labels.numpy().astype(int)
    y_true.extend(true_idx.tolist())
    y_pred.extend(preds_idx.tolist())

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# 2) Confusion matrix and classification report
cm = confusion_matrix(y_true, y_pred)
print("Classification report:\n")
print(classification_report(y_true, y_pred, target_names=val_ds.class_names))

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=val_ds.class_names, yticklabels=val_ds.class_names, cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix on Validation Set")
plt.show()

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

IMG_SIZE = (224, 224)

# Resize datasets
def resize_dataset(ds):
    def _resize(image, label):
        image = tf.image.resize(image, IMG_SIZE)
        return image, label
    return ds.map(_resize, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)

train_ds_resized = resize_dataset(train_ds)
val_ds_resized = resize_dataset(val_ds)

# Build model
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(*IMG_SIZE, 3))
base_model.trainable = False  # Freeze base layers

model_tl = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.3),
    layers.Dense(128, activation="relu"),
    layers.Dense(len(train_ds.class_names), activation="softmax")
])

model_tl.compile(optimizer=Adam(learning_rate=1e-4),
                 loss="sparse_categorical_crossentropy",
                 metrics=["accuracy"])

# Callbacks
es = EarlyStopping(monitor="val_loss", patience=3, restore_best_weights=True)
rlr = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2)

# Train
history = model_tl.fit(
    train_ds_resized,
    validation_data=val_ds_resized,
    epochs=12,
    callbacks=[es, rlr]
)

# Evaluate
val_loss, val_acc = model_tl.evaluate(val_ds_resized)
print(f"‚úÖ Validation accuracy: {val_acc:.3f}")

# Save for Gradio
model_tl.save("iris_mobilenetv2_fixed.h5")
print("‚úÖ Saved new model as iris_mobilenetv2_fixed.h5")

# ‚úÖ Fine-tuning
base_model.trainable = True

# Freeze all layers except the top 30
for layer in base_model.layers[:-30]:
    layer.trainable = False

model_tl.compile(optimizer=Adam(learning_rate=1e-5),  # smaller LR for fine-tuning
                 loss="sparse_categorical_crossentropy",
                 metrics=["accuracy"])

fine_tune_history = model_tl.fit(
    train_ds_resized,
    validation_data=val_ds_resized,
    epochs=10,
    callbacks=[es, rlr]
)

val_loss, val_acc = model_tl.evaluate(val_ds_resized)
print(f"üî• Fine-tuned Validation Accuracy: {val_acc:.3f}")

model_tl.save("iris_mobilenetv2_finetuned.h5")
print("‚úÖ Saved fine-tuned model as iris_mobilenetv2_finetuned.h5")

import os

for root, dirs, files in os.walk("/content"):
    for d in dirs:
        if "train" in d.lower():
            print("üìÇ Possible train folder:", os.path.join(root, d))

import os

for item in os.listdir("/content"):
    path = os.path.join("/content", item)
    if os.path.isdir(path):
        print("üìÅ", item)
    else:
        print("üìÑ", item)

import os

for item in os.listdir("/content/flower_images"):
    path = os.path.join("/content/flower_images", item)
    if os.path.isdir(path):
        print("üìÅ", item, "‚Üí", len(os.listdir(path)), "items")
    else:
        print("üìÑ", item)

import os, shutil
from sklearn.model_selection import train_test_split

base_dir = "/content/flower_images"
train_dir = "/content/flowers/train"
val_dir = "/content/flowers/val"

os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

# Split each class
for cls in os.listdir(base_dir):
    cls_path = os.path.join(base_dir, cls)
    if os.path.isdir(cls_path):
        images = os.listdir(cls_path)
        train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)

        os.makedirs(os.path.join(train_dir, cls), exist_ok=True)
        os.makedirs(os.path.join(val_dir, cls), exist_ok=True)

        for img in train_imgs:
            shutil.copy(os.path.join(cls_path, img), os.path.join(train_dir, cls, img))
        for img in val_imgs:
            shutil.copy(os.path.join(cls_path, img), os.path.join(val_dir, cls, img))

print("‚úÖ Dataset successfully split into Train and Validation folders!")

for sub in ["train", "val"]:
    print(f"\nüìÇ {sub.upper()} DATA:")
    for cls in os.listdir(f"/content/flowers/{sub}"):
        count = len(os.listdir(f"/content/flowers/{sub}/{cls}"))
        print(f"  {cls}: {count} images")

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers, models

# Data augmentation
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
)
val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_data = train_datagen.flow_from_directory("dataset/train", target_size=(224,224))
val_data = val_datagen.flow_from_directory("dataset/val", target_size=(224,224))

# Base model frozen completely
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(224,224,3))
base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(3, activation='softmax')
])

model.compile(optimizer=Adam(learning_rate=2e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_data, validation_data=val_data, epochs=20)

print(train_data.class_indices)

import gradio as gr
import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing import image

# Load trained model
model = tf.keras.models.load_model("iris_mobilenetv2_final.h5")

# Class labels
class_names = ['iris-setosa', 'iris-versicolour', 'iris-virginica']

# Prediction function with threshold check
def predict_iris(img):
    img = img.convert("RGB")
    img = img.resize((224, 224))  # MobileNetV2 input size
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    preds = model.predict(img_array)
    confidence = float(np.max(preds[0]))
    class_idx = np.argmax(preds[0])

    # Confidence threshold
    if confidence < 0.6:
        return {"‚ùå Unknown / Not an Iris flower": confidence}
    else:
        return {class_names[class_idx]: confidence}

# Gradio interface
app = gr.Interface(
    fn=predict_iris,
    inputs=gr.Image(type="pil"),
    outputs=gr.Label(num_top_classes=3),
    title="üå∏ Iris Flower Classification (MobileNetV2)",
    description=(
        "Upload an image of an Iris flower (Setosa, Versicolour, or Virginica). "
        "If the model isn‚Äôt confident, it will mark it as Unknown."
    ),
    examples=[
        ["iris-0befdbb7d3eeab5d4f851083ca266f4a1f0236c3a70ed2c3b1038571b117893b.jpg"],
        ["iris-1f941001f508ff1bd492457a90da64e52c461bfd64587a3cf7c6bf1bcb35adab.jpg"]
    ]
)

app.launch(share=True)