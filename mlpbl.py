# -*- coding: utf-8 -*-
"""mlpbl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LnuUrqihaizTPM1oCGU2WMjEuQ6V5O88
"""

!pip install -q mlxtend

# Commented out IPython magic to ensure Python compatibility.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Optional helper (for decision region plotting)
from mlxtend.plotting import plot_decision_regions

# Make plots show inside the notebook
# %matplotlib inline

sns.set(style="whitegrid")

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Load CSV dataset
df = pd.read_csv('Iris.csv')

# Display first 5 rows
df.head()

df.info()
df.describe()
df.isnull().sum()

df['Species'].value_counts()

import seaborn as sns
import matplotlib.pyplot as plt

# Pairplot - visualize relationships between features
sns.pairplot(df, hue='Species')
plt.show()

# Heatmap - show correlations
plt.figure(figsize=(8,5))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

from sklearn.model_selection import train_test_split

# Separate features and labels
X = df.drop(columns=['Id', 'Species'])
y = df['Species']

# Split data into train (80%) and test (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Logistic Regression
lr = LogisticRegression(max_iter=200)
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)
lr_acc = accuracy_score(y_test, lr_pred)

# KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)
knn_acc = accuracy_score(y_test, knn_pred)

# SVM
svm = SVC(kernel='linear')
svm.fit(X_train, y_train)
svm_pred = svm.predict(X_test)
svm_acc = accuracy_score(y_test, svm_pred)

# Print results
print(f"Logistic Regression Accuracy: {lr_acc:.2f}")
print(f"KNN Accuracy: {knn_acc:.2f}")
print(f"SVM Accuracy: {svm_acc:.2f}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# visualize for SVM
cm = confusion_matrix(y_test, svm_pred, labels=svm.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svm.classes_)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix - SVM Model")
plt.show()

from sklearn.metrics import classification_report

print("Classification Report (SVM Model):")
print(classification_report(y_test, svm_pred))

import joblib
import os

from sklearn.preprocessing import LabelEncoder

# Create and fit label encoder
le = LabelEncoder()
le.fit(df['Species'])

import joblib

model_file = "svm_iris_model.pkl"
le_file = "labelencoder_iris.pkl"

joblib.dump(svm, model_file)
joblib.dump(le, le_file)

print("Saved successfully:", model_file, "and", le_file)

import joblib

# Save both files in Colab environment
joblib.dump(svm, "svm_iris_model.pkl")
joblib.dump(le, "labelencoder_iris.pkl")

print("✅ Saved model and encoder in Colab workspace")

from google.colab import files

# Download the files directly to your laptop
files.download("svm_iris_model.pkl")
files.download("labelencoder_iris.pkl")

from google.colab import files
import joblib

uploaded = files.upload()   # upload svm_iris_model.pkl
svm = joblib.load("svm_iris_model.pkl")
print("Model loaded successfully ✅")

uploaded = files.upload()   # upload labelencoder_iris.pkl
le = joblib.load("labelencoder_iris.pkl")
print("LabelEncoder loaded successfully ✅")

import joblib
import numpy as np
import pandas as pd



# Example sample values
sample = np.array([[5.8, 2.7, 5.1, 1.9]])  # sepalL, sepalW, petalL, petalW

# If you trained on a DataFrame with these column names, use the same names to avoid warnings:
col_names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
sample_df = pd.DataFrame(sample, columns=col_names)

# Make prediction using the DataFrame (avoids the feature-name warning)
pred = svm.predict(sample_df)[0]

# Now handle both possible return types
# If model was trained on numeric encoded labels, pred will be numeric -> use le.inverse_transform
# If model was trained on string labels, pred is already the species name (string)
if isinstance(pred, (int, np.integer)):
    # numeric label
    pred_label = le.inverse_transform([pred])[0]
else:

    pred_label = pred

print("Raw prediction (model output):", pred)
print("Final species label:", pred_label)

!pip install -q gradio

#  Gradio app code
import gradio as gr
import joblib
import numpy as np
import pandas as pd


svm = joblib.load("svm_iris_model.pkl")
# label encoder might not exist if model trained on string labels; handle safely
try:
    le = joblib.load("labelencoder_iris.pkl")
except:
    le = None

col_names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']

def predict_iris(sepal_length, sepal_width, petal_length, petal_width):
    sample = np.array([[sepal_length, sepal_width, petal_length, petal_width]])
    sample_df = pd.DataFrame(sample, columns=col_names)
    pred = svm.predict(sample_df)[0]
    # interpret prediction
    if isinstance(pred, (int, np.integer)) and le is not None:
        label = le.inverse_transform([pred])[0]
    else:
        label = pred  # already string
    return label

# Build Gradio interface
iface = gr.Interface(
    fn=predict_iris,
    inputs=[
        gr.Number(label="Sepal Length (cm)", value=5.8),
        gr.Number(label="Sepal Width (cm)", value=2.7),
        gr.Number(label="Petal Length (cm)", value=5.1),
        gr.Number(label="Petal Width (cm)", value=1.9),
    ],
    outputs=gr.Textbox(label="Predicted Species"),
    title="Iris Flower Classifier",
    description="Enter 4 measurements to predict iris species.",
    allow_flagging="never"
)

# Launch the app (set share=True to get a public URL)
iface.launch(share=True)

# 1. Compute metrics for multiple models
from sklearn.metrics import classification_report, accuracy_score, mean_absolute_error, mean_squared_error
import numpy as np
import pandas as pd

# Ensure we have a fitted label encoder for numeric conversions
from sklearn.preprocessing import LabelEncoder
if 'le' not in globals():
    le = LabelEncoder()
    le.fit(df['Species'])

# Convert true labels to numeric
y_test_num = le.transform(y_test)

models = {
    "LogisticRegression": (lr, lr_pred),
    "KNN": (knn, knn_pred),
    "SVM": (svm, svm_pred)
}

metrics_list = []
for name, (model, pred) in models.items():
    # Pred may be strings or numeric
    if isinstance(pred[0], (str,)):
        pred_num = le.transform(pred)
    else:
        pred_num = np.array(pred).astype(int)

    acc = accuracy_score(y_test, pred)
    # classification report (string labels)
    creport = classification_report(y_test, pred, output_dict=True)
    # regression style metrics on numeric labels (not typical but OK to show)
    mae = mean_absolute_error(y_test_num, pred_num)
    mse = mean_squared_error(y_test_num, pred_num)
    rmse = np.sqrt(mse)

    metrics_list.append({
        "model": name,
        "accuracy": acc,
        "mae": mae,
        "mse": mse,
        "rmse": rmse,
        "precision_macro": creport['macro avg']['precision'],
        "recall_macro": creport['macro avg']['recall'],
        "f1_macro": creport['macro avg']['f1-score']
    })

metrics_df = pd.DataFrame(metrics_list)
metrics_df

import matplotlib.pyplot as plt
plt.figure(figsize=(7,4))
plt.bar(metrics_df['model'], metrics_df['accuracy'])
plt.ylim(0,1.05)
for i,v in enumerate(metrics_df['accuracy']):
    plt.text(i, v+0.02, f"{v:.2f}", ha='center', fontsize=12)
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.show()

import seaborn as sns
from sklearn.metrics import confusion_matrix

def plot_cm(true, pred, title):
    cm = confusion_matrix(true, pred, labels=le.inverse_transform([0,1,2]))
    # confusion_matrix expects numeric labels or label order; we'll map manually:
    # to keep it robust, transform to numeric then reorder
    try:
        true_num = le.transform(true)
        pred_num = le.transform(pred) if isinstance(pred[0], str) else np.array(pred).astype(int)
    except:
        true_num = np.array(true)
        pred_num = np.array(pred)
    cm = confusion_matrix(true_num, pred_num)
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=le.classes_, yticklabels=le.classes_)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title(title)
    plt.show()

# Plot for each model
plot_cm(y_test, lr_pred, "Confusion Matrix - Logistic Regression")
plot_cm(y_test, knn_pred, "Confusion Matrix - KNN")
plot_cm(y_test, svm_pred, "Confusion Matrix - SVM")

# Install Gradio if not installed
!pip install -q gradio

import gradio as gr
import joblib
import numpy as np
import pandas as pd
import os

# Load model and label encoder (assumes they are in the workspace)
svm = joblib.load("svm_iris_model.pkl")
try:
    le = joblib.load("labelencoder_iris.pkl")
except:
    # If label encoder not available but model predicts strings, create a dummy le
    le = None

col_names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']
csv_path = "/tmp/iris_predictions.csv"

# Ensure CSV file has a header if not exists
if not os.path.exists(csv_path):
    pd.DataFrame(columns=col_names + ["PredictedSpecies"]).to_csv(csv_path, index=False)

def predict_and_save(sepal_length, sepal_width, petal_length, petal_width, save):
    sample = np.array([[sepal_length, sepal_width, petal_length, petal_width]])
    sample_df = pd.DataFrame(sample, columns=col_names)
    pred = svm.predict(sample_df)[0]
    # Normalize pred to string label
    if isinstance(pred, (int, np.integer)) and le is not None:
        pred_label = le.inverse_transform([pred])[0]
    else:
        pred_label = pred

    # Append to CSV if save is True
    if save:
        row = dict(zip(col_names, [sepal_length, sepal_width, petal_length, petal_width]))
        row["PredictedSpecies"] = pred_label
        pd.DataFrame([row]).to_csv(csv_path, mode='a', header=False, index=False)


    return pred_label, csv_path

# Build Gradio UI
iface = gr.Interface(
    fn=predict_and_save,
    inputs=[
        gr.Number(label="Sepal Length (cm)", value=5.8),
        gr.Number(label="Sepal Width (cm)", value=2.7),
        gr.Number(label="Petal Length (cm)", value=5.1),
        gr.Number(label="Petal Width (cm)", value=1.9),
        gr.Checkbox(label="Save this prediction to CSV", value=True)
    ],
    outputs=[
        gr.Textbox(label="Predicted Species"),
        gr.File(label="Download Predictions CSV")
    ],
    title="Iris Flower Classifier",
    description="Enter measurements and optionally save the prediction. Download the CSV of saved predictions.",
    allow_flagging="never"
)

# Launch
iface.launch(share=True)